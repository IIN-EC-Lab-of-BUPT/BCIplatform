# 通信模块使用说明

## 通信平台的部署

### 服务器端部署

1. 拷贝 kafka-service.tar 文件到一个空目录中, 并在该目录下打开终端

   以下过程建议全程联网: 
   **强烈建议在 Linux 操作系统下进行服务器端的部署!** 
   **建议操作系统: Cent OS 与 Ubuntu** 
   **并向电脑管理员知悉该系统的”sudo”密码**
   首先在计算机上安装 docker, 具体安装步骤, 请搜索: 
   “XXX 操作系统安装 docker”

2. 获知该电脑的 IP 地址:

   https://blog.csdn.net/topgun_chenlingyun/article/details/8073651 

3. 进行 docker 的预配置:

   a） 若直接执行”docker ps -a”出现下面字样: 
   Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker 
   daemon running? 
   请运行 systemctl start docker.service 
   b）设置非 root 账号不用 sudo 直接执行 docker 命令 
   https://blog.csdn.net/boling_cavalry/article/details/106590784

4. 进行通信平台服务器的部署

   执行命令：

   docker load -i kafka-service.tar 
   docker run -d -it -p 0.0.0.0:2222:22 -p 0.0.0.0:60000:9092 -p 0.0.0.0:60001:2181 --
   name="KafkaServerContainer" -h KafkaServerDocker --add-

   host=server:**192.168.223.128** --restart=always kafkaservie:2.0 /data/kafka.sh 
   （黑体部分 ip 改成部署主机的地址即可）
   docker restart KafkaServerContainer

### 服务器端部署可能出现的问题

1.  通信平台服务所需的配置: 
16 核+32GB 内存,外加 200GB 的硬盘(SSD,磁盘阵最佳) 
2. IP 地址有多个, 选择哪一个? 
请选择”网卡 eth0”所对应的 IP 地址 
3. 部署完成后,使用”通信平台客户端部署文档”中提到的测试脚本测试,发现无法进行通信, 
请在通信服务器所在操作系统开启 60000 与 60001 端口的入站许可 
4.  若有其他问题, 请联系北京邮电大学. 

### 客户端部署

1. 打开 hosts 文件: 
    a) 找到自己 hosts 文件所在位置进行修改 
    b) Windows 在开始屏幕搜索 “notepad”，右键选择 “以管理员身份运行” 记事本程
    序，按下 Ctrl+O 定位到 hosts 文件修改并直接保存。 
    c) OS X 在 Finder 窗口按下［前往］［前往文件夹…］，输入 /etc 回车，将 hosts 
    文件拖拽到桌面，双击修改保存，再将其拖拽回 /etc ，鉴定替换。 
    d) Linux 在终端运行命令 sudo gedit /etc/hosts 修改。 

2. 然后在最后一行键入以下内容: 
    **通信服务器 IP 地址 server** 
    如下图所示: 

  ![通信平台部署1](C:\Users\admin\Desktop\开源图片\通信平台部署1.png)

  然后保存, 即可进行通信平台客户端的部署。

3. (可选)尝试 ping 一下 server, 看看能够 ping 通:

![通信平台2](C:\Users\admin\Desktop\开源图片\通信平台2.png)

## 通信平台不同包的介绍

### Kafka4Python

下载本模块安装包(kafka_client.zip)并解压后，请妥善放置其解压文件，安装完成后再次移动、改动或删除其解压文件将导致该模块无法正常使用。

本模块安装时应在命令行中转到安装包“setup.py“文件所在路径下，激活待安装的虚拟环境后执行如下代码：

```
python setup.py develop
```

另：本模块依赖于第三方类库confluent-kafka，该类库推荐python3版本3.8及以下。如果安装包安装失败，请尝试运行以下代码后重试：

```
pip install confluent-kafka
```

配置以及使用示例位于 kafka_client_usage.zip 压缩包 , 请解压后运行

使用者只需关注生产者类、消费者类及 topic 操作中的 “ 创建 topic” 方法

#### topic操作：

```python 
class CommunicationInitial(CommunicationInitialInterface)
```

##### 查询topic列表

```python
@staticmethod
def topicQuery(communicationCharactor: QueryInterface)
```

```python
:param communicationCharactor: a instance of interface "QueryInterface"
:return: a list of topic name
```

可能异常：

TopicQueryFailed # 通常由于网络问题导致，发生后建议检查同Kafka服务器的网络联通性，或联系管理
员检查Kafka服务健康度

###### 创建topic

```python
python setup.py develop
pip install confluent-kafka
class CommunicationInitial(CommunicationInitialInterface)
@staticmethod
def topicQuery(communicationCharactor: QueryInterface)
:param communicationCharactor: a instance of interface "QueryInterface"
:return: a list of topic name
TopicQueryFailed # 通常由于网络问题导致，发生后建议检查同Kafka服务器的网络联通性，或联系管理
员检查Kafka服务健康度
@staticmethod
def topicCreate(topic, confPath, num_partitions= 1 , replication_factor= 1 )
```

可能异常：

```python
NoConfigFileException # 配置文件不存在
WrongConfigContextException # 配置文件内容有误
TopicCreateFailed # topic创建失败，发生后建议检查同Kafka服务器的网络联通性，或联系管理员检
查Kafka服务健康度
```

###### 删除topic

```python
@staticmethod
def topicDelete(topic, confPath):
```

```python
:param topic: this param is the name of the topic that you want to delete. type:
str
:param confPath: broker configuration, "bootstrap.servers" must be set
:return: a dict of futures for each topic, keyed by the topic name. type:
dict(<topic_name, future>)
```

可能异常:

```python
NoConfigFileException # 配置文件不存在
WrongConfigContextException # 配置文件内容有误
TopicCreateFailed # topic删除失败
```



#### 生产者：

```
class CommunicationProducer(CommunicationProducerInterface, QueryInterface)
```

调用者只需要关注 init 、 send 和 close 的用法

##### 初始化

```python
def __init__(self, confPath)
```

```python
:param confPath: this param is the path of the producer config file that you
want to use. type: str
```

##### 发送消息

```python
send(self, topic: str, value: bytes, timeout: float = 1, key=None) -> None
```

```python
:param topic: this param is the topic name that you want to send message to,
type: str
:param value: this param is the message context, type: bytes
:param timeout: this param is the timeout for sending a msg, but that doesn't
mean the msg sending is failed
:param key: this param isn't used currently
:return: None
```

可能异常：

```python
WrongMessageValueType # 消息类型非bytes
```

##### 关闭

```python
def close(self, timeout: float = 1) -> None
```

```python
release resources
:param: timeout: this param is the flush timeout before closed
:return: None
```

推送生产者队列中的全部消息

#### 消费者：

```python
class CommunicationConsumer(CommunicationConsumerInterface, QueryInterface)
```

调用者只需要关注 init 、 receive 、 timeStampReceive 和 stop 的用法

##### 初始化

```python
def __init__(self, confPath, consumerId)
```

```python
:param confPath: this param is the path of the producer config file that you
want to use. type: str
:param consumerId: this param should be unique in the system, UUID suggested.
type: str
```

##### 订阅

```python
def subscribe(self, topic: str) -> None
```

```python
:param topic: this param is the topic this consumer need to subscribe
```

可能异常

```python
TopicNotAvailableException # topic不存在或其他原因订阅失败，发生后建议手动创建topic，或
检查同Kafka服务器的网络联通性，或联系管理员检查Kafka服务健康度
```

##### 取消订阅

```python
def unsubscribe(self) -> None
```

##### 接收消息

```python
def receive(self) -> bytes
```

```python
:return: unpacking message received in timeout. type: bytes or None(when there
is no message in timeout)
```

##### 接收带有时间戳的消息

```python
def timeStampReceive(self) -> list
```

```python
:return: a list of timestamp and message value.
the first element in the list is a tulpe of timestamp. the first element is
timestamp type,
which is a number in 0, 1 or 2.
0 means the timestamp isn't available, in this case, the return timestamp should
be ignore.
1 means the return timestamp is the number of milliseconds of the message
creation time.
2 means the return timestamp is the number of milliseconds of the broker receive
time.
the first element in the list is bytes of message value.
type: [(int, int), bytes] or None(when there is no message in timeout)
```

##### 关闭

```python
def close(self) -> None
```

取消订阅、关闭消费者

#### 配置文件说明

##### CommunicationInitial类的配置文件

配置文件路径：./communicationModuleUsage/config/initial-config.json

###### 话题管理配置文件示例

{

“bootstrap.servers”: “server:60000”,

“retryLimit”: “3”

}

###### 字段含义：

- **bootstrap.servers** ：type：string。（下同）通信服务器地址，如Kafka服务部署方式或服务器IP有变，请询问管理员具体地址及使用方式。（在默认部署方式下，需在计算机中添加“<host名><IP地址>”映射，然后在此处填入host名和端口号。host名（或IP）与端口号之间以英文冒号分隔。）

- **retryLimit** ： type：string，内容需为大于等于 0 的int型数字。

  CommunicationInitial.topicCreate方法重试次数。如果网络环境较差，建议将该字段设为较大值，但如果该字段值过大，将导致用户无法及时发现网络异常。

##### CommunicationProducer类的配置文件

配置文件路径：./communicationModuleUsage/config/producer-config.json

###### 生产者配置文件示例

{

"bootstrap.servers": "server:60000",
"debugLogEnable": "false",
"linger.ms": "0",

"retryLimit": "0",

"realtimeFlush": "true”
}

###### 字段含义：

- **debugLogEnable** ： type：string，enum：{false，true}，大小写不敏感。（下同）是否开启生产者/消费者debug级别的日志记录，如果开启，则生产者/消费者将在每次生产/消费动作完成后记录一条debug级别的日志，在大量、低间隔进行生产/消费活动时建议关闭该日志。

- **linger.ms** ：type：string，内容需为int型数字。对生产者发送速度有较高要求时建议将该字段设为较小值。

- **retryLimit** ： type：string，内容需为大于等于 0 的int型数字。CommunicationProducer.listTopics方法重试次数。如果网络环境较差，建议将该字段设为较大值，但如果该字段值过大，将导致用户无法及时发现网络异常。

- **realtimeFlush** ： type：string，enum：{false，true}，大小写不敏感。是否开启实时推送。如果开启该功能可以保证消息尽快发出，但开启后会导致CommunicationProducer.send方法在被调用后产生大致10ms的阻塞。

##### CommunicationConsumer类的配置文件

配置文件路径：./communicationModuleUsage/config/consumer-config.json

###### 消费者配置文件示例

{

"bootstrap.servers": "server:60000",
"auto.offset.reset": "latest",
"enable.auto.commit": "False",

"retryLimit": "3",

"debugLogEnable": "False”
}

###### 字段含义：

- auto.offset.reset ： type：string，enum：{latest，earliest，none}，大小写敏感。消费者从消息队列的何处开始消费。该参数不建议改动，默认给出的设置将使消费者从其启动时的最新消息开始消费。

- enable.auto.commit ：该参数不建议改动。

- retryLimit ： type：string，内容需为大于等于 0 的int型数字。CommunicationConsumer.listTopics方法重试次数。如果网络环境较差，建议将该字段设为较大值，但如果该字段值过大，将导致用户无法及时发现网络异常。

### Kafka4Matlab

#### 概述

Kafka 是一个开源软件，在很多地方都被用于特定的流处理。Matalab 是一个优秀的数学计
算工具和仿真平台。由于各种实验需要使用 Matlab，流处理成为必不可少的功能。幸运的
是，Kafka 可以提供流数据源。kafka4matlab 为 Matlab 用户提供了调用 Kafka 的 API。我们从
安装 Kafka4matlab

#### 安装 Kafka4matlab

1、准备 eegplatformcommunicationmodule4j - master. jar
2、在 matlab 的命令窗口中输入 disp(Java. Lang. System. GetProperty (' Java. Ext dirs')); 查询到
自己的 matlab Java 环境下的 ext 目录。
3、将 eegplatformcommunicationmodule4j - master.jar 放入 ext 目录，重启 matlab
4、添加到源路径

#### 类

##### KafkaConsumerImpl

kafkaConsumerImpl 提供了一种为 kafka 平台注册消费者并向 kafka 发送消息的方法。
Since: kafka4matlab1.0
Inherits：CommunicationConsumer

###### Properties:

| Type          | Name    |
| ------------- | ------- |
| KafkaConsumer | consume |

###### Functions:

| Type              | Function                                        |
| ----------------- | ----------------------------------------------- |
| KafkaConsumerImpl | Initial(String configPath,Long consumerTimeout) |
| Void              | subscribe(string topicName)                     |
| Void              | unsubscribe()                                   |
| [bytes,string]    | timeStampReceive()                              |
| Void              | clear()                                         |
| Void              | close()                                         |

##### KafkaProducerImpl

kafkaProducerImpl 提供了一种为 kafka 平台注册生产者和从 kafka 接收消息的方法。
Since: kafka4matlab1.0
Inherits：CommunicationpProducer

###### Properties:

| Type          | Name     |
| ------------- | -------- |
| KafkaProducer | producer |

###### Functions:

| Type              | Function                         |
| ----------------- | -------------------------------- |
| KafkaConsumerImpl | Initial(String configPath)       |
| Void              | send(string topic,bytes message) |
| Void              | close()                          |

##### KafkaTopicOperatorImpl

kafkaOperatorImpl 提供了一种为 kafka 创建主题和管理主题的方法。
Since: kafka4matlab1.0
Inherits：CommunicationTopicOperator

###### Properties:

| Type                   | Name          |
| ---------------------- | ------------- |
| KafkaTopicOperatorImpl | topicOperator |

###### Functions:

| Type                   | Function                  |
| ---------------------- | ------------------------- |
| KafkaTopicOperatorImpl | Initial(String configPath |
| Void                   | topicCreate(string topic) |
| List                   | topicQuery()              |
| Void                   | topicDelete(string topic  |

##### Configuration

consumerConfig

producerConfig

topicOperatorConfig

###### Examples

consumer example:

http://10.112.37.62:2020/cy/kafka4matlab/-/blob/master/usage/KafkaConsumer.m
producer example；
http://10.112.37.62:2020/cy/kafka4matlab/-/blob/master/usage/KafkaProducer.m
topicOperator example：
http://10.112.37.62:2020/cy/kafka4matlab/-/blob/master/usage/KafkaTopicOperator.m

Note:此接口只支持字节流!示例中的是字符串发送方法!

### Kafka4Matlab

解压文件 "communication4j_jar.zip"
使用时请仿写usage包中的用例。
usage.config包内所有的配置文件需根据实际情况填入bootstrap.servers地址，使用测试环境运行时，
该地址为server:60000，使用前需现在自己的电脑上添加hosts映射，内容为:
**“安装通信平台服务器的地址 server”。**
例如:

![通信平台java](C:\Users\admin\Desktop\开源图片\通信平台java.png)

usage包中的用例在实例化相应操作类时应根据实际情况填入配置文件地址。

## Kafka topic命名规范

*注：*

*本规范提供根据多种应用场景划分的不同命名方式，请各项目负责人按项目特点进行选择，尽量做长远打算。该命名规则主要面向多人合作项目中的应用/子系统间交互场景，应用内部topic命名在保证唯一性的前提下不做过多干涉。*

 *一定不要做：*

*1)      在topic名中使用“.”、“_”符号做字段分隔。推荐使用“-”作为间隔符号。*

*2)      topic名在代码中写死。topic的实际名称应在配置文件中给出，并作为实参被读入应用程序，传给代码中的形参。*

### 应用场景一：广播式

该类topic中承载的消息具有来源固定、无特殊指向性等特点，如脑电数据传输话题。

该类topic命名方式如下（本文中如无特殊说明，topic名中字段均以“-”连接）：

 **消息源唯一标识        消息类型        其他备注信息（可缺省）**   

消息源唯一标识、消息类型的具体内容需要项目设计者按项目需求进行选择，如脑机接口大赛系统中的脑电数据采集话题，可以选择以受试者ID（假设是“3483087817”）作为消息源唯一标识（因为同一时间同一被试只能产生一种脑电数据），以“EEGData”作为消息类型。在消息源唯一标识不足以提供唯一性区分时，可按需追加其他备注信息。

usage：“3483087817-EEGData”

### 应用场景二：远程调用式

该类topic中承载的消息具有来源不固定、去向固定等特点。这种场景下，我们实际上将该topic的消费方视为一个提供远程调用服务的服务端，它不关心topic中的消息是由谁发出的（可能有大量不同的发送者），只需要完成该topic消息内容中规定的任务。消费方通过轮询该topic中调用请求的方式执行任务。

该类topic命名方式如下：

 **消息接收者唯一标识      消息接收者提供的服务类型      其他备注信息**   

例如，主系统中存在一个数据库代理子系统（假设子系统ID为3483087817），该子系统提供对数据库操作的远程调用，其提供的服务可以分为新增数据记录（insert）、查询数据记录（query）这两类，则该数据库代理子系统维护的topic共2个，分别为负责接收远程调用新增请求的“3483087817-insert” 和负责接收远程调用查询请求的“ 3483087817-query”。

 

注：使用该类topic时，如需接收调用结果，请求发送方应在请求消息中指定请求序列号以及接收请求调用结果的topic名；提供调用服务的程序应按协议解析该请求，并按指定的请求序列号向给定的接收调用结果的topic发送调用结果。

### 应用场景三：点对点式

在某类topic承载的消息来源去向都确定的情况下，可采用点对点式topic命名规范。

该类topic命名方式如下：

 **消息接收源唯一标识        To        消息接收者唯一标识        其他备注信息**   

例如，主系统中存在两个需要双向频繁交换业务消息的子系统，如刺激子系统（ID为3483087817）和处理子系统（ID为4688768934），则该子系统组维护的topic共2个，分别为刺激子系统向处理子系统发送消息的topic“3483087817-To-4688768934”和处理子系统向刺激子系统发送消息的topic“4688768934-To-3483087817”。









# Trigger模块使用说明

- 本模块基于**Python 3.8**版本。
- trigger发送模块的具体实现位于impl包中。
- ParallelTriggerImpl是使用inpoutx64驱动发送并口trigger的实现方式。
- **使用者只需要参考TriggerInterface中的接口说明调用TriggerController即可。**
- Trigger用例程序位于TriggerUsage中。

> 注意：由于并口每次发送trigger后需要重新将引脚电平置为低电平，所以不要连续调用send()，应保证一定的调用间隔，否则会出现异常。

## Trigger模块部署工作

### 一. 检查是否可正确识别端口

**右键此电脑—管理—设备管理器**，检查并口是否可以正确识别，如果未正确识别则应安装相应驱动。

并口驱动：请按照并口卡的型号搜索其相应驱动。

正确识别并口后请记录其端口号。 并口端口号查看：**右键并口（LPT1）—属性—资源—I/O范围**，记录7FF8即可。

### 二. 安装inpoutx64驱动

使用并口发送trigger前需要安装inpoutx64对应的驱动，驱动位于**trigger—TriggerDependency—1—Win32**下，双击InstallDriver.exe即可安装驱动。

### 三. 配置并口

#### 通过PCI-Express 转并口 发送Trigger 配置

关闭PCI-Express并口 链接状态电源管理：设置 - 电源和睡眠 - 其他电源设置 - 选择电源计划 - 选择“高性能模式”- 更改计划设置 - 更改高级电源设置 - 找到“PCI Express”-链接状态电源管理： 设置为“关闭”(系统默认即为"关闭"）。

#### 485接口接收Trigger配置

如果接收trigger时使用到了485线（如Neuracle的TriggerBox使用485线接收Trigger），则需要进行相应设置。我的电脑-右键-属性-左侧边栏"设备管理器" - 与TriggerBox 连接的USB接口（安装TriggerBox驱动后，通常位于 端口(COM和LPT)-USB Serial Port(COM X) 位置) - 右键”属性“-端口设置-高级。
BM选项中 **延迟计时器(毫秒) - 修改设置为'1'**(Windows 10 系统安装驱动后默认设置为16ms)。之后**修改对应COM端口号为COM12。**

## Trigger模块接口说明

### 实例化TriggerController

```python
trigger_ctrl = TriggerController(port: int)
"""
:param port: 并口所对应的端口，如:并口输入十进制32760或十六进制0x7FF8
"""
```

### 打开端口

```python
trigger_ctrl.open() -> bool
"""
开启端口的方法
:return: 成功返回True，失败返回False
"""
```

### 发送Trigger事件

```python
trigger_ctrl.send(event: int) -> bool
"""
发送trigger的方法
:param event: 发送的trigger值，trigger值应为1-255之间的整数
:return: 发送成功返回True，发送失败返回False
"""
```

### 关闭端口

```python
trigger_ctrl.close() -> bool
"""
关闭端口的方法
:return: 关闭成功返回True，关闭失败返回False
"""
```

## Trigger模块其他使用注意事项

- 默认情况下，trigger控制器不是单例，如果需要可以将TriggerController中相应代码解除注释。
- `open()` 方法保证了线程安全，但是原则上不应该多次调用。
- `send()` 方法未做线程安全处理，以保证发送trigger的性能，不要多线程调用该方法。
- `open() send() close()`  方法都设置了返回值，建议接收返回值并判断打开/发送/关闭操作是否成功，如果未成功，可以再次调用。
- 由于并口每次发送trigger后需要重新将引脚电平置为低电平，所以不要连续调用send()，应保证一定的调用间隔，否则会出现异常。



# 采集模块使用说明

## 采集模块部署工作

### 一.Neuroscan的安装

若已经安装Neuroscan curry 8 采集软件,请跳过本章节的步骤, 并开始部署数据采集软件。

#### 1.安装Scan 4.5 软件(若已安装请直接阅读第2步)

① 运行.\Scan\目录下Setup程序安装全部软件。

② 安装主目录下.\Sca451Hotfix文件。

**(注意上面两步中不要进行电脑的重启,请在完成第④步后再重启)**

③ 进入NeuroScan的安装目录(通常在C:\Program Files (x86)\Neuroscan目录下)找到Drivers文件夹。

④ 进入Drivers文件夹下SynAmp2目录，右键SynAmp2_64.ini文件选择安装。

⑤  进入Drivers文件夹下Sentinel目录，安装Sentinel Protection Installer 7.5.0（PS： Win7 及以下系统安装Sentinel System Driver Installer 7.5.2;Win 10 系统需要上网搜索对应的Sentinel HL驱动，也可使用已下载好的(Win10补充驱动(加密狗)文件夹下驱动程序)。

⑥ 进入NeuroScan安装目录(通常在C:\Program Files (x86)\Neuroscan目录下),运行Ampinst.exe文件，选择放大器为SynAmps 2。

#### 可能出现的问题

① 提示加密狗无效：

请检查设备管理器中Sentinel 驱动是否安装好，如果为感叹号，则按照上文⑤步骤安装。

② 打开NeuroScan采集软件后，所有导联呈现正弦波形：按照上文第⑥步骤运行Ampinst.exe文件，并设置放大器为SynAmps 2。安装过程中建议最好保持加密狗一直插在系统上。

③ 上文③步骤中找不到Drivers文档, 或者④步骤中找不到SynAmp2_64.ini文件, 请卸载软件, 更换软件安装位置并重新安装(此问题为Scan4.5 随机bug, 如果无法安装, 请联系北京邮电大学)。

④ 步骤⑥中可能出现电脑蓝屏, 重启,并重复该步骤即可。

⑤ 上述步骤可能出现诸如无法安装未认证驱动的问题, 请参照下面链接解决:

​	https://zhuanlan.zhihu.com/p/36973815

#### 2 安装Neuroscan Curry 8 软件

① 解压curry.zip文件, 得到如下两个可执行文件: 

![数据采集模块安装curry8](C:\Users\admin\Desktop\开源图片\数据采集模块安装curry8.png)

② 请先安装Curry803CourseSetupBeijing.exe,再安装Curry803Patch.exe。

### 二.数据采集软件部署

**开始部署前, 请确保已经完成通信服务器, 通信客户端的部署。**

#### 部署方式

1.将Collect 文件夹 复制到工程文件夹。

2.安装numpy和loguru依赖(并确保已经安装通信平台Python语言客户端)。

3.在DeviceModule目录下的config的NeuroScanEEG.json文件中配置相关参数，包括端口号port，导联数n_chan ,kafka话题topic（与数据池话题topic一致）, 日志级别log_level(其中0表示无日志，1表示仅记录基本信息，2表示记录所有信息)。

4.启动采集脚本：运行CollectMain.py，打开CURRY8发送脑电数据（前后顺序可以改变）。

#### 使用说明

1.CollectMain函数中Device_confPath 代表NeuroScan配置文件路径，confPath代表通信平台生产者配置文件路径，initialPath 代表通信平台初始化配置路径。

2.采集端发送到数据池的数据中，第一行包含trigger信息，其余行表示脑电信息,具体每行对应导联是与curry 8的设置相关的。

3.CURRY8意外关闭或者未开启时，如果运行了采集端，采集端会等待连接到CURRY8，最多等待30次重连。

#### 可能出现的问题

1.提示channel数不匹配：

在NeuroScanEEG.json文件中修改n_chan为正确导联数。

2.提示CANNOT CONNECT TO Kafka：

在NeuroScanEEG.json文件中修改topic为正确topic或检查kafka是否部署正确，在kafka配置文件中正确配置Kafka参数。

3.提示'CONNECT FAILED, RETRYING FOR x TIME':

在NeuroScanEEG.json文件中修改port与采集设备相同，或检查采集设备是否打开。

 如果问题, 请联系北京邮电大学。

## 采集模块说明文档

### 文件

- collect_test支持NeuroScan采集。
- TobiiCollect支持Tobii采集。
- Collect0504支持NeuroScan和Tobii采集，切换设备时只需更改配置。

### 依赖

- 依赖需要包含confluent_kafka包，可以使用psychopy中的python.exe作为解释器或者pip添加该包。

- 如果库中没有EEGPlatformCommunicationModule4py，那么
  - 在gitlab的http://10.112.37.62:2020/lcx/eegplatformcommunicationmodule4py路径下下载安装包到本地。			
  - 如果是windows系统，直接将EEGPlatformCommunicationModule4py复制到采集模块中，项目不报错即可。
- 如果在库中有EEGPlatformCommunicationModule4py，项目不报错就可以。
- 在本机hosts文件中添加kafka服务器地址，如10.112.120.252 server.

### 测试

- 依然从gitlab的路径下拉取测试代码，位于communcationModuleUsage包下。
- 修改过topic和配置文件就可以只用ConsumerUsage.py接收kafka发来的数据。
- 没有数据源可以使用CURRY模拟器模拟。

## 采集模块接口说明

本系统用于NeuroScan原始数据的处理和转发，使用socket与脑电数据发送端通信，再使用kafka将处理后的数据转发给处理端。

### 采集入口：

```python
if __name__ == '__main__':
    collect = Collect(Device_confPath)
    collect.run(confPath,initialPath)
```

### kafka配置文件：

路径

```python
confPath = r"./MessageQueue/usage/config/producer-config.json" 
```

配置内容：主机加端口

```python
{"bootstrap.servers": "server:60000","linger.ms": "1"}
```

### NeuroScan配置文件：

路径

```python
Device_confPath = r"./DeviceModule/config/NeuroScanEEG.json"
```

配置内容

```python
{
  "device_name": "NeuroScan",
  "hostname": "localhost",
  "port": 4455,
  "n_chan": 10,
  "topic":"NeuroScanEEG",
  "log_level":2
}
```

*其中device_name为设备名称，hostname为主机IP，port为socket通信端口，应该和采集设备端口保持一致，n_chan为采集端输入的导数，topic为kafka通信的话题,log_level为日志级别*



### 建立采集数据处理转发线程（调用Collect时创建）：

```python
"""
参数说明：
线程名threadName（自定义, string）
设备名device（自定义, string）
导联数n_chan（不包括Trigger,int）
运行放大器驱动软件的终端的IP地址hostname(string)
放大器驱动软件用于发送数据的tcp端口号port(int)
发送至kafka的topic名称(string)
"""
thread_data_server = NeuroScanEEGThread(threadName='NeuroScanEEG', device=target_device['device_name'],n_chan=target_device['n_chan'],
hostname=target_device['hostname'], port=target_device['port'],
topic=target_device['topic']) 
```

### 与数据池建立kafka连接（调用Collect.run时进行连接）：

```python
self.thread_data_server.connect_kafka(confPath,initialPath)
```



### 与采集设备建立socket连接（调用Collect.run时进行连接）：

```python
notconnect = thread_data_server.connect()
if notconnect:
    thread_data_server.logger.debug("Can't connect recorder")
    raise TypeError("Can't connect recorder, Please open the hostport ")
else:
    thread_data_server.start()
```

*使用socket与采集设备通信，连接不成功时继续重连，直到连接成功或者尝试次数超过19*

*kafka和socket连接成功后，start采集线程*

### 数据处理流程:

```python
def read_thread(self):   
    """
    visit eegthread, catch sockets and parse sockets, append parsed data to ringbuffer
    """
    self.requestInfo()
    self.requestChannelInfo()
    self.receiveThread=threading.Thread(target=self.parseData)
    self.sendThread=threading.Thread(target=self.sendData)
    self.receiveThread.start()
    self.sendThread.start()
```

在线程中先完成基础信息的获取，之后分别开启两个线程，完成数据采集和数据转发的功能。

### requestInfo函数：

```python
def requestInfo(self):
    """
    通过与采集设备socket通信获得基本信号，即通道数目，采样率和数据包大小
    """
```

### requestChannelInfo函数：

```python
def requestChannelInfo(self):
    """
    通过与采集设备socket通信请求导联信息
    """
```

### parseData函数：

```python
def parseData(self):
    """
    handle data,message and event
    """
```

*作为线程，持续从采集端接收消息和数据，根据消息头部的信息得知发来的数据类型，对不同类型做出相应处理。如果根据消息头部的信息得知发来的是数据信息，对数据进行解析和打包操作。如果根据消息头部的信息得知发来的是阻抗信息，暂停接收数据只接收阻抗，接收完毕后继续接收数据。做完降采样的操作之后将处理好的数据放入先入先出队列queue之中。*

### 可能异常：

```python
socketException
```

```python
self.info["eegChan"] != self.n_chan
```

*如果socket通信中断，在except中调用connect()继续连接，连接完成后可继续收发数据不受中断影响；如果发来的导数与NeuroScan中预设的导数不同，直接断开socket连接。*

### sendData函数：

```python
def sendData(self):
    """
    send bytestream data to kafka
    """
```

*当队列queue中有数据的时候，从中获取到数据并转化为字节流发送到kafka服务器*





